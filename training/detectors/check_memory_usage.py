"""
è¯Šæ–­ GenD æ¨¡å‹æ˜¾å­˜ä½¿ç”¨æƒ…å†µçš„è„šæœ¬
"""
import torch
import torch.nn as nn
from gend_detector import GenDDetector, CLIPEncoder, LinearProbe

def check_model_memory():
    """æ£€æŸ¥æ¨¡å‹æ˜¾å­˜å ç”¨"""
    print("=" * 80)
    print("GenD æ¨¡å‹æ˜¾å­˜ä½¿ç”¨è¯Šæ–­")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿé…ç½®
    config = {
        'backbone': 'openai/clip-vit-large-patch14',
        'head': 'linear',
        'num_classes': 2,
        'freeze_feature_extractor': True,
        'loss': {
            'ce_labels': 1.0,
            'uniformity': 0.5,
            'alignment_labels': 0.1,
        }
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = GenDDetector(config=config).cuda()
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°é‡ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,} ({total_params * 4 / 1024**3:.2f} GB @ FP32)")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params * 4 / 1024**3:.2f} GB @ FP32)")
    print(f"  å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params * 4 / 1024**3:.2f} GB @ FP32)")
    print(f"  å¯è®­ç»ƒæ¯”ä¾‹: {trainable_params / total_params * 100:.4f}%")
    
    # æµ‹è¯•ä¸åŒbatch sizeçš„æ˜¾å­˜å ç”¨
    batch_sizes = [32, 64, 128, 256, 512]
    resolution = 224
    
    print(f"\nğŸ” ä¸åŒ Batch Size çš„æ˜¾å­˜å ç”¨æµ‹è¯• (åˆ†è¾¨ç‡: {resolution}x{resolution}):")
    print("-" * 80)
    
    for bs in batch_sizes:
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        
        # åˆ›å»ºè¾“å…¥
        images = torch.randn(bs, 3, resolution, resolution).cuda()
        labels = torch.randint(0, 2, (bs,)).cuda()
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            data_dict = {'image': images, 'label': labels}
            pred_dict = model(data_dict, inference=True)
        
        forward_mem = torch.cuda.max_memory_allocated() / 1024**3
        
        # è®­ç»ƒæ¨¡å¼ï¼ˆåŒ…å«æ¢¯åº¦ï¼‰
        model.train()
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        
        data_dict = {'image': images, 'label': labels}
        pred_dict = model(data_dict, inference=False)
        losses = model.get_losses(data_dict, pred_dict)
        
        # åå‘ä¼ æ’­
        losses['overall'].backward()
        
        train_mem = torch.cuda.max_memory_allocated() / 1024**3
        
        # æ¸…ç†æ¢¯åº¦
        model.zero_grad()
        torch.cuda.empty_cache()
        
        print(f"  Batch Size {bs:3d}: å‰å‘ {forward_mem:.2f} GB | è®­ç»ƒ {train_mem:.2f} GB")
    
    # æ£€æŸ¥å®é™…batch size
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"  1. å¦‚æœæ˜¾å­˜ä½¿ç”¨ç‡ä½ï¼Œå¯ä»¥å°è¯•:")
    print(f"     - å¢åŠ  batch size åˆ° 512 æˆ–æ›´å¤§")
    print(f"     - è§£å†»éƒ¨åˆ† CLIP å±‚ï¼ˆè®¾ç½® unfreeze_layersï¼‰")
    print(f"     - ä½¿ç”¨æ›´å¤§çš„ CLIP æ¨¡å‹ï¼ˆå¦‚æœæ˜¾å­˜å……è¶³ï¼‰")
    print(f"  2. å½“å‰é…ç½®ä¸‹ï¼Œbatch size 256 çš„æ˜¾å­˜å ç”¨åº”è¯¥çº¦ä¸º 8-10 GB")
    print(f"  3. å¦‚æœåªæœ‰ 9 GBï¼Œè¯´æ˜:")
    print(f"     - CLIP ç¼–ç å™¨è¢«å†»ç»“ï¼Œä¸å­˜å‚¨æ¢¯åº¦ âœ…")
    print(f"     - åªæœ‰åˆ†ç±»å¤´åœ¨è®­ç»ƒ âœ…")
    print(f"     - è¿™æ˜¯æ­£å¸¸çš„ï¼Œç¬¦åˆ GenD çš„è®¾è®¡ âœ…")
    
    print("\n" + "=" * 80)

if __name__ == '__main__':
    check_model_memory()

